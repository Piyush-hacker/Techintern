{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"This is my first Kaggle Notebook that I'll be uploading , the primary goal hereis to analyse the data and try to create a model to predict the prices and explore various data preprocessing and regression models .","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fancyimpute","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:19:47.077588Z","iopub.execute_input":"2023-03-17T08:19:47.077935Z","iopub.status.idle":"2023-03-17T08:20:03.760515Z","shell.execute_reply.started":"2023-03-17T08:19:47.077906Z","shell.execute_reply":"2023-03-17T08:20:03.759224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fasteda","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:03.762285Z","iopub.execute_input":"2023-03-17T08:20:03.762684Z","iopub.status.idle":"2023-03-17T08:20:14.417322Z","shell.execute_reply.started":"2023-03-17T08:20:03.762649Z","shell.execute_reply":"2023-03-17T08:20:14.416487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom scipy.special import boxcox1p\nimport plotly.express as px\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.metrics import r2_score\n#RFE\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,RepeatedStratifiedKFold,StratifiedKFold,KFold\nimport seaborn as sns\nfrom category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder, CatBoostEncoder\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom fasteda import fast_eda\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Import libraries for Hypertuning\nimport optuna\n\n# Import libraries for gradient boosting\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:14.418414Z","iopub.execute_input":"2023-03-17T08:20:14.418753Z","iopub.status.idle":"2023-03-17T08:20:19.620515Z","shell.execute_reply.started":"2023-03-17T08:20:14.418721Z","shell.execute_reply":"2023-03-17T08:20:19.619051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import the dataset\ndataset = pd.read_csv(\"/kaggle/input/sports-car-prices-dataset/Sport car price.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.622917Z","iopub.execute_input":"2023-03-17T08:20:19.623218Z","iopub.status.idle":"2023-03-17T08:20:19.643612Z","shell.execute_reply.started":"2023-03-17T08:20:19.623177Z","shell.execute_reply":"2023-03-17T08:20:19.642015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.645184Z","iopub.execute_input":"2023-03-17T08:20:19.645657Z","iopub.status.idle":"2023-03-17T08:20:19.669781Z","shell.execute_reply.started":"2023-03-17T08:20:19.645616Z","shell.execute_reply":"2023-03-17T08:20:19.668769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Renaming the columns to make refering them more easier\ndataset = dataset.rename(columns = {'Car Make': 'car_make',\n    'Car Model': 'car_model',\n    'Year': 'year',\n    'Engine Size (L)': 'engine_size_L',\n    'Horsepower': 'horsepower',\n    'Torque (lb-ft)': 'torque',\n    '0-60 MPH Time (seconds)': 'acceleration_seconds',\n    'Price (in USD)': 'price_usd'\n})","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.671012Z","iopub.execute_input":"2023-03-17T08:20:19.671335Z","iopub.status.idle":"2023-03-17T08:20:19.680443Z","shell.execute_reply.started":"2023-03-17T08:20:19.671307Z","shell.execute_reply":"2023-03-17T08:20:19.678759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Almost the entire dataset is given in the format of object data type to make a proper analysis \n# To do this I used List Comprehension with regular expressions to convert the data types to int or float depending on the feature\nimport re\npattern = r'^-?\\d+(?:\\.\\d+)?$'\ndataset['price_usd'] = [int(X.replace(\",\",\"\")) for X in dataset['price_usd']]\ndataset['engine_size_L'] = [float(X) if re.search(pattern,str(X)) else None for X in dataset['engine_size_L']]\ndataset['horsepower'] = [int(X) if re.search(r'^[0-9]+$',str(X)) else None for X in dataset['horsepower']]\ndataset['torque'] = [int(X) if re.search(r'^[0-9]+$',str(X)) else None for X in dataset['torque']]\ndataset['acceleration_seconds'] = [float(X) if re.search(pattern,str(X)) else None for X in dataset['acceleration_seconds']]","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.684378Z","iopub.execute_input":"2023-03-17T08:20:19.685584Z","iopub.status.idle":"2023-03-17T08:20:19.708307Z","shell.execute_reply.started":"2023-03-17T08:20:19.685469Z","shell.execute_reply":"2023-03-17T08:20:19.706381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['price_usd'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.710348Z","iopub.execute_input":"2023-03-17T08:20:19.710714Z","iopub.status.idle":"2023-03-17T08:20:19.723619Z","shell.execute_reply.started":"2023-03-17T08:20:19.710682Z","shell.execute_reply":"2023-03-17T08:20:19.722468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by Car Model and count the number of cars\ncar_counts = dataset.groupby('car_make').size().reset_index(name='counts')\n\n# Filter models with at least 10 cars\n#car_counts = car_counts[car_counts['counts'] >= 10]\n\n# Create the interactive bar chart\nfig = px.bar(car_counts, x='car_make', y='counts', title='Number of cars produced by Carmake', \n             labels={'carmodel': 'Carmake', 'counts': 'Number of cars'})\n\n# Show the plot\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:19.725171Z","iopub.execute_input":"2023-03-17T08:20:19.725737Z","iopub.status.idle":"2023-03-17T08:20:21.185006Z","shell.execute_reply.started":"2023-03-17T08:20:19.725674Z","shell.execute_reply":"2023-03-17T08:20:21.183766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"fast_eda\" module in Python is a data analysis library that provides a quick and efficient way to perform exploratory data analysis (EDA) on large datasets. The fast_eda library is designed to simplify the EDA process by providing a set of functions and tools that allow users to quickly generate descriptive statistics, visualize data, and identify potential issues in the data.","metadata":{}},{"cell_type":"code","source":"#Doing a fast Exploratory data analysis of the dataset\nfast_eda(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:21.188683Z","iopub.execute_input":"2023-03-17T08:20:21.188983Z","iopub.status.idle":"2023-03-17T08:20:30.09514Z","shell.execute_reply.started":"2023-03-17T08:20:21.188955Z","shell.execute_reply":"2023-03-17T08:20:30.093608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create an array of columns\ncolumns = np.array(dataset.columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:30.098618Z","iopub.execute_input":"2023-03-17T08:20:30.098968Z","iopub.status.idle":"2023-03-17T08:20:30.103387Z","shell.execute_reply.started":"2023-03-17T08:20:30.098937Z","shell.execute_reply":"2023-03-17T08:20:30.102566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the regression plot to understand the relationship\n#between the features and the target variables\nfor col in columns[2:]:\n    sns.regplot(x=col, y='price_usd', color = 'navy',data =dataset)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:30.104934Z","iopub.execute_input":"2023-03-17T08:20:30.106055Z","iopub.status.idle":"2023-03-17T08:20:31.647878Z","shell.execute_reply.started":"2023-03-17T08:20:30.10601Z","shell.execute_reply":"2023-03-17T08:20:31.646791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I encoded the categorical variables with Target Encoding instead of \n# Label Encoding and One Hot Encoding because it gave me better results , \n# if there are better ways to encode please let me know \nimport category_encoders as ce\ncat_features = dataset.select_dtypes(include= ['object']).columns\nencoders = ce.TargetEncoder(cols = cat_features)\ntarget = dataset[['price_usd']]\ntrain = dataset.drop(['price_usd'],axis = 1)\nencoded_features = encoders.fit_transform(train,target)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.649409Z","iopub.execute_input":"2023-03-17T08:20:31.649771Z","iopub.status.idle":"2023-03-17T08:20:31.685826Z","shell.execute_reply.started":"2023-03-17T08:20:31.649737Z","shell.execute_reply":"2023-03-17T08:20:31.68435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform skewed data into a more normal distribution using boxcox1p function\nnumeric_features = encoded_features.dtypes[encoded_features.dtypes != \"object\"].index\nfrom scipy.stats import skew\nskewed_feats = encoded_features[numeric_features].apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\nskewness = pd.DataFrame({'Skew':skewed_feats})\nskewness = skewness[abs(skewness['Skew'])>0.75]\nskewed_features = skewness.index\nfor i in skewed_features:\n    encoded_features[i] = boxcox1p(encoded_features[i],0.15)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.687442Z","iopub.execute_input":"2023-03-17T08:20:31.68787Z","iopub.status.idle":"2023-03-17T08:20:31.707275Z","shell.execute_reply.started":"2023-03-17T08:20:31.68783Z","shell.execute_reply":"2023-03-17T08:20:31.706033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Imputing the data using Multiple Imputation by Chained Equations\nfrom fancyimpute import IterativeImputer\nimputer = IterativeImputer(random_state = 4)\nencoded_imputed_features =  imputer.fit_transform(encoded_features)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.708618Z","iopub.execute_input":"2023-03-17T08:20:31.708994Z","iopub.status.idle":"2023-03-17T08:20:31.918247Z","shell.execute_reply.started":"2023-03-17T08:20:31.708955Z","shell.execute_reply":"2023-03-17T08:20:31.91725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reset_index for dataframe manually\ndataset = pd.DataFrame(data = encoded_imputed_features,columns = columns[:-1])","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.919339Z","iopub.execute_input":"2023-03-17T08:20:31.919668Z","iopub.status.idle":"2023-03-17T08:20:31.92581Z","shell.execute_reply.started":"2023-03-17T08:20:31.919635Z","shell.execute_reply":"2023-03-17T08:20:31.924051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and test set 0.8:0.2\nX_train,X_test,Y_train,Y_test = train_test_split(dataset,target,test_size=0.2, random_state = 4)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.927422Z","iopub.execute_input":"2023-03-17T08:20:31.92795Z","iopub.status.idle":"2023-03-17T08:20:31.941Z","shell.execute_reply.started":"2023-03-17T08:20:31.927907Z","shell.execute_reply":"2023-03-17T08:20:31.939584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train,Y_train)\nrfe = RFE(lm)\nrfe= rfe.fit(X_train,Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.942953Z","iopub.execute_input":"2023-03-17T08:20:31.943388Z","iopub.status.idle":"2023-03-17T08:20:31.960862Z","shell.execute_reply.started":"2023-03-17T08:20:31.943349Z","shell.execute_reply":"2023-03-17T08:20:31.959168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.torque","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.962709Z","iopub.execute_input":"2023-03-17T08:20:31.963144Z","iopub.status.idle":"2023-03-17T08:20:31.971896Z","shell.execute_reply.started":"2023-03-17T08:20:31.963106Z","shell.execute_reply":"2023-03-17T08:20:31.971083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.972766Z","iopub.execute_input":"2023-03-17T08:20:31.973059Z","iopub.status.idle":"2023-03-17T08:20:31.984067Z","shell.execute_reply.started":"2023-03-17T08:20:31.973034Z","shell.execute_reply":"2023-03-17T08:20:31.982591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new= build_model(X_train,Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:31.985682Z","iopub.execute_input":"2023-03-17T08:20:31.986014Z","iopub.status.idle":"2023-03-17T08:20:32.011207Z","shell.execute_reply.started":"2023-03-17T08:20:31.985987Z","shell.execute_reply":"2023-03-17T08:20:32.009879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With those results, the not significant columns are erased from the Linear Regression model to see if the R-squared with fewer variables keeps almost the same value. For choosing those variables the following criteria were applied:\n\nIn a numerical column only a variable is preserved if the P-value is less than 0.05\n\nAfter the analysis , the model will be trained again:","metadata":{}},{"cell_type":"code","source":"X_train_new = X_train.drop(['year','torque'], axis = 1)\nX_test = X_test.drop(['year','torque'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:32.012489Z","iopub.execute_input":"2023-03-17T08:20:32.012834Z","iopub.status.idle":"2023-03-17T08:20:32.020803Z","shell.execute_reply.started":"2023-03-17T08:20:32.012805Z","shell.execute_reply":"2023-03-17T08:20:32.019347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats = build_model(X_train_new,Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:32.022177Z","iopub.execute_input":"2023-03-17T08:20:32.02267Z","iopub.status.idle":"2023-03-17T08:20:32.042307Z","shell.execute_reply.started":"2023-03-17T08:20:32.022632Z","shell.execute_reply":"2023-03-17T08:20:32.041166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor(loss='huber', max_depth=2, n_estimators=4000,\n                          random_state=1, subsample=0.75)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:32.043914Z","iopub.execute_input":"2023-03-17T08:20:32.044578Z","iopub.status.idle":"2023-03-17T08:20:32.050938Z","shell.execute_reply.started":"2023-03-17T08:20:32.044516Z","shell.execute_reply":"2023-03-17T08:20:32.049479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train_new,Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:32.05221Z","iopub.execute_input":"2023-03-17T08:20:32.052621Z","iopub.status.idle":"2023-03-17T08:20:40.529914Z","shell.execute_reply.started":"2023-03-17T08:20:32.052586Z","shell.execute_reply":"2023-03-17T08:20:40.528047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model.predict(X_test)\nY_pred_train = model.predict(X_train_new)\nprint('RMSE train data: %.3f, RMSE test data: %.3f' % (\nnp.sqrt(mean_squared_error(Y_train,Y_pred_train)),\nnp.sqrt(mean_squared_error(Y_test,Y_pred))))\nprint('R2 train data: %.3f, R2 test data: %.3f' % (\nr2_score(Y_train,Y_pred_train),\nr2_score(Y_test,Y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:40.531509Z","iopub.execute_input":"2023-03-17T08:20:40.531978Z","iopub.status.idle":"2023-03-17T08:20:40.590417Z","shell.execute_reply.started":"2023-03-17T08:20:40.531952Z","shell.execute_reply":"2023-03-17T08:20:40.589405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV,ElasticNet\nlasso = LassoCV(cv=10, random_state=0).fit(X_train_new, Y_train)\n# Evaluate model on test data\nY_pred = lasso.predict(X_test)\nY_pred_train = lasso.predict(X_train_new)\nprint('MSE train data: %.3f, MSE test data: %.3f' % (\nnp.sqrt(mean_squared_error(Y_train,Y_pred_train)),\nnp.sqrt(mean_squared_error(Y_test,Y_pred))))\nprint('R2 train data: %.3f, R2 test data: %.3f' % (\nr2_score(Y_train,Y_pred_train),\nr2_score(Y_test,Y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:40.591905Z","iopub.execute_input":"2023-03-17T08:20:40.592613Z","iopub.status.idle":"2023-03-17T08:20:40.696339Z","shell.execute_reply.started":"2023-03-17T08:20:40.592578Z","shell.execute_reply":"2023-03-17T08:20:40.695096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators = 100,\n                              random_state = 1,\n                              n_jobs = -1)\nforest.fit(X_train_new,Y_train)\nforest_train_pred = forest.predict(X_train_new)\nforest_test_pred = forest.predict(X_test)\nprint('MSE train data: %.3f, MSE test data: %.3f' % (\nnp.sqrt(mean_squared_error(Y_train,forest_train_pred)),\nnp.sqrt(mean_squared_error(Y_test,forest_test_pred))))\nprint('R2 train data: %.3f, R2 test data: %.3f' % (\nr2_score(Y_train,forest_train_pred),\nr2_score(Y_test,forest_test_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-03-17T08:20:40.700723Z","iopub.execute_input":"2023-03-17T08:20:40.701048Z","iopub.status.idle":"2023-03-17T08:20:41.170748Z","shell.execute_reply.started":"2023-03-17T08:20:40.701019Z","shell.execute_reply":"2023-03-17T08:20:41.169026Z"},"trusted":true},"execution_count":null,"outputs":[]}]}